{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import time\n",
    "import json\n",
    "from collections import Counter\n",
    "import ast\n",
    "\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "from typing import List, Tuple\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tp_fp(true_labels, predicted_labels):\n",
    "    true_labels = ast.literal_eval(true_labels)  # Convert to list\n",
    "    predicted_labels = ast.literal_eval(predicted_labels)\n",
    "\n",
    "    true_counts = Counter(true_labels)\n",
    "    pred_counts = Counter(predicted_labels)\n",
    "\n",
    "    tp_counts = Counter(t for t, p in zip(true_labels, predicted_labels) if t == p)\n",
    "    fp_counts = Counter(p for t, p in zip(true_labels, predicted_labels) if t != p)\n",
    "\n",
    "    results = []\n",
    "    for label in true_counts:\n",
    "        tp_rate = (tp_counts[label] / true_counts[label]) * 100 if true_counts[label] else 0\n",
    "        fp_rate = (fp_counts[label] / pred_counts[label]) * 100 if pred_counts[label] else 0\n",
    "        results.append((label, tp_rate, fp_rate))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "name = \"../library_test/credentials/identity_attributes_driving_license.csv\"\n",
    "df_labels = pd.read_csv(name)\n",
    "df_labels[\"JSON information\"] = df_labels[\"JSON information\"].apply(lambda x: json.loads(x))\n",
    "df_labels[\"number_attributes\"]= 12+df_labels[\"Number of general additional informations\"]+3*df_labels[\"Number of categories\"]+df_labels[\"Number of additional inforations of each categories\"].apply(lambda x: sum(map(int, x.split(','))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all rows\n",
    "tp_fp_results = []\n",
    "score_results = []\n",
    "name_folder = \"model trial 4 100 redo\"\n",
    "runs = [2,3,4,5,12,13,14,15,16,17,18]\n",
    "\n",
    "for i in range(1):\n",
    "    name_csv = f\"model_run{i+1}_simplified.csv\"\n",
    "    df = pd.read_csv(f\"{name_folder}/{name_csv}\", index_col=0)\n",
    "\n",
    "    for j, row in df.iterrows():\n",
    "        # Recovery of the True Positive and False Positive for each label based on its regex and models\n",
    "        row_results = compute_tp_fp(row[\"test_labels\"], row[\"predictions\"])\n",
    "        for label, tp_rate, fp_rate in row_results:\n",
    "            tp_fp_results.append({\n",
    "                \"row\": j,\n",
    "                \"type_model\": row[\"type_model\"],\n",
    "                \"regex\": row[\"regex\"],\n",
    "                \"Personal Number\": label,\n",
    "                \"TP%\": tp_rate,\n",
    "                \"FP%\": fp_rate\n",
    "            })\n",
    "        # Recovery of the score of each models\n",
    "        score_results.append({\n",
    "            \"type_model\": row[\"type_model\"],\n",
    "            \"regex\": row[\"regex\"],\n",
    "            \"score\": row[\"score\"],\n",
    "            \"score2\": row[\"score2\"],\n",
    "            \"score10\": row[\"score10\"]\n",
    "        })\n",
    "        \n",
    "\n",
    "# Convert to DataFrame\n",
    "df_tp_fp_results = pd.DataFrame(tp_fp_results).merge(df_labels[[\"Personal Number\", \"number_attributes\"]], on=\"Personal Number\", how=\"left\")\n",
    "df_score_results =  pd.DataFrame(score_results)\n",
    "\n",
    "# Group by type_model, regex, and Personal Number, then compute mean and variance\n",
    "df_tp_fp_results_groupby = df_tp_fp_results.groupby([\"type_model\", \"regex\", \"Personal Number\"]).agg(\n",
    "    TP_Mean=(\"TP%\", \"mean\"),\n",
    "    TP_Var=(\"TP%\", \"var\"),\n",
    "    FP_Mean=(\"FP%\", \"mean\"),\n",
    "    FP_Var=(\"FP%\", \"var\")\n",
    ").reset_index()\n",
    "\n",
    "df_tp_fp_results_groupby_number_attribute_only = df_tp_fp_results.groupby([\"type_model\", \"regex\", \"number_attributes\"]).agg(\n",
    "    TP_Mean=(\"TP%\", \"mean\"),\n",
    "    TP_Var=(\"TP%\", \"var\"),\n",
    "    FP_Mean=(\"FP%\", \"mean\"),\n",
    "    FP_Var=(\"FP%\", \"var\")\n",
    ").reset_index()\n",
    "\n",
    "# Group by type_model, regex, and Personal Number, then compute mean and variance\n",
    "df_score_results_groupby = df_score_results.groupby([\"type_model\", \"regex\"]).agg(\n",
    "    Score_Mean=(\"score\", \"mean\"),\n",
    "    Score_Var=(\"score\", \"var\"),\n",
    "    Score2_Mean=(\"score2\", \"mean\"),\n",
    "    Score2_Var=(\"score2\", \"var\"),\n",
    "    Score10_Mean=(\"score10\", \"mean\"),\n",
    "    Score10_Var=(\"score10\", \"var\")\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "df_tp_fp_results_groupby_number_attribute_only.to_csv(f\"{name_folder}/df_tp_fp_results_groupby_number_attribute_only.csv\")\n",
    "df_tp_fp_results_groupby.to_csv(f\"{name_folder}/df_tp_fp_results_groupby.csv\")\n",
    "df_score_results_groupby.to_csv(f\"{name_folder}/df_score_results_groupby.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
