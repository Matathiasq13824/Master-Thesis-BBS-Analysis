{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter Notebook used to analyse the average and variance accuracy of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import json\n",
    "from collections import Counter\n",
    "import ast\n",
    "\n",
    "# Path to the folder containing the models\n",
    "name_folder = \"model_run\"\n",
    "# Number of csv files \"model_run{i+1}_simplified.csv\"\n",
    "number_models = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function use to calculate the true and false positive probability for every classified label.\n",
    "def compute_tp_fp(true_labels, predicted_labels):\n",
    "    true_labels = ast.literal_eval(true_labels)\n",
    "    predicted_labels = ast.literal_eval(predicted_labels)\n",
    "\n",
    "    true_counts = Counter(true_labels)\n",
    "    pred_counts = Counter(predicted_labels)\n",
    "\n",
    "    tp_counts = Counter(t for t, p in zip(true_labels, predicted_labels) if t == p)\n",
    "    fp_counts = Counter(p for t, p in zip(true_labels, predicted_labels) if t != p)\n",
    "\n",
    "    results = []\n",
    "    for label in true_counts:\n",
    "        tp_rate = (tp_counts[label] / true_counts[label]) * 100 if true_counts[label] else 0\n",
    "        fp_rate = (fp_counts[label] / pred_counts[label]) * 100 if pred_counts[label] else 0\n",
    "        results.append((label, tp_rate, fp_rate))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recovery of the initial identities to recover their number of attributes\n",
    "name = \"../typescript/credentials/identity_attributes_driving_license.csv\"\n",
    "df_labels = pd.read_csv(name)\n",
    "df_labels[\"JSON information\"] = df_labels[\"JSON information\"].apply(lambda x: json.loads(x))\n",
    "df_labels[\"number_attributes\"]= 12+df_labels[\"Number of general additional informations\"]+3*df_labels[\"Number of categories\"]+df_labels[\"Number of additional inforations of each categories\"].apply(lambda x: sum(map(int, x.split(','))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recovery of the average and mean of the scores of the models\n",
    "score_results = []\n",
    "for i in range(number_models):\n",
    "    name_csv = f\"model_run{i+1}_simplified.csv\"\n",
    "    df = pd.read_csv(f\"{name_folder}/{name_csv}\", index_col=0)\n",
    "    for j, row in df.iterrows():\n",
    "        # Recovery of the score of each models\n",
    "        score_results.append({\n",
    "            \"type_model\": row[\"type_model\"],\n",
    "            \"regex\": row[\"regex\"],\n",
    "            \"score\": row[\"score\"],\n",
    "            \"score2\": row[\"score2\"],\n",
    "            \"score10\": row[\"score10\"]\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_score_results =  pd.DataFrame(score_results)\n",
    "\n",
    "# Group by type_model and regex then compute mean and variance\n",
    "df_score_results_groupby = df_score_results.groupby([\"type_model\", \"regex\"]).agg(\n",
    "    Score_Mean=(\"score\", \"mean\"),\n",
    "    Score_Var=(\"score\", \"var\"),\n",
    "    Score2_Mean=(\"score2\", \"mean\"),\n",
    "    Score2_Var=(\"score2\", \"var\"),\n",
    "    Score10_Mean=(\"score10\", \"mean\"),\n",
    "    Score10_Var=(\"score10\", \"var\")\n",
    ").reset_index()\n",
    "\n",
    "# Store the result\n",
    "df_score_results_groupby.to_csv(f\"{name_folder}/df_score_results_groupby.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recovery of the TP and FP percentage and variance of the models for each number of attributes\n",
    "\n",
    "tp_fp_results = []\n",
    "score_results = []\n",
    "for i in range(number_models):\n",
    "    name_csv = f\"model_run{i+1}_simplified.csv\"\n",
    "    df = pd.read_csv(f\"{name_folder}/{name_csv}\", index_col=0)\n",
    "\n",
    "    for j, row in df.iterrows():\n",
    "        # Recovery of the True Positive and False Positive for each label based on its regex and models\n",
    "        row_results = compute_tp_fp(row[\"test_labels\"], row[\"predictions\"])\n",
    "        for label, tp_rate, fp_rate in row_results:\n",
    "            tp_fp_results.append({\n",
    "                \"row\": j,\n",
    "                \"type_model\": row[\"type_model\"],\n",
    "                \"regex\": row[\"regex\"],\n",
    "                \"Personal Number\": label,\n",
    "                \"TP%\": tp_rate,\n",
    "                \"FP%\": fp_rate\n",
    "            })\n",
    "        \n",
    "\n",
    "# Convert to DataFrame\n",
    "df_tp_fp_results = pd.DataFrame(tp_fp_results).merge(df_labels[[\"Personal Number\", \"number_attributes\"]], on=\"Personal Number\", how=\"left\")\n",
    "df_score_results =  pd.DataFrame(score_results)\n",
    "\n",
    "# Group by type_model, regex, and Personal Number, then compute mean and variance\n",
    "df_tp_fp_results_groupby = df_tp_fp_results.groupby([\"type_model\", \"regex\", \"Personal Number\"]).agg(\n",
    "    TP_Mean=(\"TP%\", \"mean\"),\n",
    "    TP_Var=(\"TP%\", \"var\"),\n",
    "    FP_Mean=(\"FP%\", \"mean\"),\n",
    "    FP_Var=(\"FP%\", \"var\")\n",
    ").reset_index()\n",
    "\n",
    "# Group by type_model, regex, and number of attribute, then compute mean and variance\n",
    "df_tp_fp_results_groupby_number_attribute_only = df_tp_fp_results.groupby([\"type_model\", \"regex\", \"number_attributes\"]).agg(\n",
    "    TP_Mean=(\"TP%\", \"mean\"),\n",
    "    TP_Var=(\"TP%\", \"var\"),\n",
    "    FP_Mean=(\"FP%\", \"mean\"),\n",
    "    FP_Var=(\"FP%\", \"var\")\n",
    ").reset_index()\n",
    "\n",
    "# Store the data\n",
    "df_tp_fp_results_groupby_number_attribute_only.to_csv(f\"{name_folder}/df_tp_fp_results_groupby_number_attribute_only.csv\")\n",
    "df_tp_fp_results_groupby.to_csv(f\"{name_folder}/df_tp_fp_results_groupby.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
