{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "from typing import List, Tuple\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(features_kept, file_name, n_rows = None):\n",
    "\n",
    "    \"\"\"Function to load data that will be used for classification.\n",
    "\n",
    "    Args:\n",
    "        You can provide the args you want.\n",
    "    Returns:\n",
    "        features (list): the list of features you extract from every trace\n",
    "        labels (list): the list of identifiers for each trace\n",
    "    \n",
    "    An example: Assume you have traces (trace1...traceN) for cells with IDs in the\n",
    "    range 1-N.  \n",
    "    \n",
    "    You extract a list of features from each trace:\n",
    "    features_trace1 = [f11, f12, ...]\n",
    "    .\n",
    "    .\n",
    "    features_traceN = [fN1, fN2, ...]\n",
    "\n",
    "    Your inputs to the classifier will be:\n",
    "\n",
    "    features = [features_trace1, ..., features_traceN]\n",
    "    labels = [1, ..., N]\n",
    "\n",
    "    Note: You will have to decide what features/labels you want to use and implement \n",
    "    feature extraction on your own.\n",
    "    \"\"\"\n",
    "\n",
    "    features_data = (pd.read_csv(file_name, nrows=n_rows)\n",
    "    .filter(regex=features_kept)\n",
    "    .to_numpy().transpose())\n",
    "    \n",
    "    features = features_data[1:].transpose()\n",
    "    labels = features_data[0]\n",
    "    del features_data\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(train_features, train_labels, test_features, test_labels, name_model, type_model):\n",
    "\n",
    "    \"\"\"Function to perform classification, using a \n",
    "    Random Forest. \n",
    "\n",
    "    Reference: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "    \n",
    "    Args:\n",
    "        train_features (numpy array): list of features used to train the classifier\n",
    "        train_labels (numpy array): list of labels used to train the classifier\n",
    "        test_features (numpy array): list of features used to test the classifier\n",
    "\n",
    "    Returns:\n",
    "        predictions: list of labels predicted by the classifier for test_features\n",
    "\n",
    "    Note: You are free to make changes the parameters of the RandomForestClassifier().\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize a random forest classifier. Change parameters if desired.\n",
    "    if type_model == \"hist\":\n",
    "        clf = HistGradientBoostingClassifier(verbose=2)\n",
    "    elif type_model == \"neuronal\":\n",
    "        clf = MLPClassifier(hidden_layer_sizes=(1000,100),verbose= True)\n",
    "    else:\n",
    "        clf = RandomForestClassifier(verbose= 2, n_jobs=-1)\n",
    "    # Train the classifier using the training features and labels.\n",
    "    clf.fit(train_features, train_labels)\n",
    "    # Use the classifier to make predictions on the test features.\n",
    "    predictions = clf.predict(test_features)\n",
    "    proba = clf.predict_proba(test_features)\n",
    "    #clf do already some of the work for us\n",
    "    score = clf.score(test_features, test_labels)\n",
    "    joblib.dump(clf, name_model, compress=9)\n",
    "\n",
    "    \n",
    "    return predictions, proba, score, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_crossval(features, labels, run, folds=10, model= \"hist\", regex = \"\", name_proofs = \"\", output_folder = \"\"):\n",
    "\n",
    "    \"\"\"Function to perform cross-validation.\n",
    "    Args:\n",
    "        features (list): list of features\n",
    "        labels (list): list of labels\n",
    "        run (int): number of the run to save the model\n",
    "        folds (int): number of fold for cross-validation (default=10)\n",
    "    Returns:\n",
    "        You can modify this as you like.\n",
    "    \n",
    "    This function splits the data into training and test sets. It feeds\n",
    "    the sets into the classify() function for each fold. \n",
    "\n",
    "    You need to use the data returned by classify() over all folds \n",
    "    to evaluate the performance.         \n",
    "    \"\"\"\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=folds)\n",
    "    df = pd.DataFrame(columns= [\n",
    "        \"name_model\",\n",
    "        \"type_model\",\n",
    "        \"regex\",\n",
    "        \"trial_name\",\n",
    "        \"params_model\",\n",
    "        \"proofs_name\",\n",
    "        \"total_number_proofs\",\n",
    "        \"len_test_index\",\n",
    "        \"test_index\",\n",
    "        \"test_labels\",\n",
    "        \"predictions\",\n",
    "        # \"proba\", # Too large to save\n",
    "        \"score\",\n",
    "        \"score2\",\n",
    "        \"score10\",\n",
    "    ])\n",
    "    labels = np.array(labels)\n",
    "    features = np.array(features)\n",
    "    total_top_2_accuracy = 0.0\n",
    "    total_top_10_accuracy = 0.0\n",
    "    total_score = 0.0\n",
    "    for idx, indexes in enumerate(kf.split(features, labels)):\n",
    "        print(\"==== New Fold ====\")\n",
    "        name_model = f\"model_{idx}_run{run}\"\n",
    "        train_index, test_index = indexes\n",
    "        X_train, X_test = features[train_index], features[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        print(\"here\")\n",
    "        print(len(X_train))\n",
    "        print(\"here\")\n",
    "        predictions, proba, score, model_full = classify(X_train, y_train, X_test, y_test, f\"{output_folder}/{name_model}\", model)\n",
    "        total_score += score\n",
    "        score2 = calculate_accuracy(proba, y_test, 2)\n",
    "        score10 = calculate_accuracy(proba, y_test, 10)\n",
    "        total_top_2_accuracy += score2\n",
    "        total_top_10_accuracy += score10\n",
    "        df = pd.concat([pd.DataFrame([[\n",
    "            name_model, #done\n",
    "            str(type(model_full)), #done\n",
    "            regex,\n",
    "            output_folder,\n",
    "            str(model_full.get_params()), #done\n",
    "            name_proofs,\n",
    "            str(len(labels)), #done\n",
    "            str(len(test_index)), #done\n",
    "            str(test_index.tolist()), #done\n",
    "            str(y_test.tolist()), #done\n",
    "            str(predictions.tolist()), #done\n",
    "            # str(proba.tolist()),\n",
    "            str(score), #done\n",
    "            str(score2), #done\n",
    "            str(score10), #done\n",
    "        ]], columns=df.columns), df], ignore_index=True)\n",
    "        del model_full\n",
    "    df.to_csv(f\"{output_folder}/model_run{run}_simplified.csv\")\n",
    "        \n",
    "    print(\"Total aveage prediction rate: {}\".format(total_score / folds))\n",
    "    print(\"Average prediction rate for top 2: {}\".format(total_top_2_accuracy / folds))\n",
    "    print(\"Average prediction rate for top 10: {}\".format(total_top_10_accuracy / folds))\n",
    "\n",
    "\n",
    "def sort_predictions(predictions_proba: NDArray, y_test: NDArray) -> List[Tuple[int, List[Tuple[int, float]]]]:\n",
    "    ordered_predictions = []\n",
    "    for y, pred_prob in zip(y_test, predictions_proba):\n",
    "        sorted_proba = sorted([(i + 1, prob) for i, prob in enumerate(pred_prob) if prob > 0], key=lambda x: x[1], reverse=True)\n",
    "        ordered_predictions.append((y, sorted_proba))\n",
    "    return ordered_predictions\n",
    "\n",
    "def calculate_accuracy(predictions_proba: NDArray, y_test: NDArray, N: int = 100) -> float:\n",
    "    sorted_predictions = sort_predictions(predictions_proba, y_test)\n",
    "    nb_IN_N_tops = sum(y in [pred[0] for pred in sorted_pred[:N]] for y, sorted_pred in sorted_predictions)\n",
    "    return float(nb_IN_N_tops) / len(predictions_proba)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_crossval_evaluation(features, labels, folder_model, run, folds=10, regex = \"\", name_proofs = \"\"):\n",
    "\n",
    "    \"\"\"Function to perform cross-validation.\n",
    "    Args:\n",
    "        features (list): list of features\n",
    "        labels (list): list of labels\n",
    "        run (int): number of the run to save the model\n",
    "        folds (int): number of fold for cross-validation (default=10)\n",
    "    Returns:\n",
    "        You can modify this as you like.\n",
    "    \n",
    "    This function splits the data into training and test sets. It feeds\n",
    "    the sets into the classify() function for each fold. \n",
    "\n",
    "    You need to use the data returned by classify() over all folds \n",
    "    to evaluate the performance.         \n",
    "    \"\"\"\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=folds)\n",
    "    df = pd.DataFrame(columns= [\n",
    "        \"name_model\",\n",
    "        \"type_model\",\n",
    "        \"regex\",\n",
    "        \"trial_name\",\n",
    "        \"params_model\",\n",
    "        \"proofs_name\",\n",
    "        \"total_number_proofs\",\n",
    "        \"len_test_index\",\n",
    "        \"test_index\",\n",
    "        \"test_labels\",\n",
    "        \"predictions\",\n",
    "        # \"proba\", # Too large to save\n",
    "        \"score\",\n",
    "        \"score2\",\n",
    "        \"score10\",\n",
    "    ])\n",
    "    labels = np.array(labels)\n",
    "    features = np.array(features)\n",
    "    total_top_2_accuracy = 0.0\n",
    "    total_top_10_accuracy = 0.0\n",
    "    total_score = 0.0\n",
    "    for idx, indexes in enumerate(kf.split(features, labels)):\n",
    "        print(\"==== New Fold ====\")\n",
    "        train_index, test_index = indexes\n",
    "        X_train, X_test = features[train_index], features[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        model = joblib.load(f\"{folder_model}/model_{idx}_run{run}_half\")\n",
    "        print(\"model loaded\")\n",
    "        predictions = model.predict(X_test)\n",
    "        proba = model.predict_proba(X_test)\n",
    "        score = model.score(X_test, y_test)\n",
    "        total_score += score\n",
    "        score2 = calculate_accuracy(proba, y_test, 2)\n",
    "        score10 = calculate_accuracy(proba, y_test, 10)\n",
    "        total_top_2_accuracy += score2\n",
    "        total_top_10_accuracy += score10\n",
    "        df = pd.concat([pd.DataFrame([[\n",
    "            f\"model_{idx}_run{run}\", #done\n",
    "            str(type(model)), #done\n",
    "            regex,\n",
    "            folder_models,\n",
    "            str(model.get_params()), #done\n",
    "            name_proofs,\n",
    "            str(len(labels)), #done\n",
    "            str(len(test_index)), #done\n",
    "            str(test_index.tolist()), #done\n",
    "            str(y_test.tolist()), #done\n",
    "            str(predictions.tolist()), #done\n",
    "            # str(proba.tolist()),\n",
    "            str(score), #done\n",
    "            str(score2), #done\n",
    "            str(score10), #done\n",
    "        ]], columns=df.columns), df], ignore_index=True)\n",
    "        del model\n",
    "    df.to_csv(f\"{folder_models}/model_run{run}_simplified.csv\")\n",
    "        \n",
    "    print(\"Total aveage prediction rate: {}\".format(total_score / folds))\n",
    "    print(\"Average prediction rate for top 2: {}\".format(total_top_2_accuracy / folds))\n",
    "    print(\"Average prediction rate for top 10: {}\".format(total_top_10_accuracy / folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/var/folders/cp/c9cg0sd95bdg_22hr4zb39s40000gn/T/ipykernel_43247/3958049250.py:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  regex = \"Personal Number|number_attributes|Size|proof_array_\\d+\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== New Fold ====\n",
      "here\n",
      "450000\n",
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 100building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 8 of 100\n",
      "\n",
      "building tree 7 of 100\n",
      "building tree 1 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "regex = \"Personal Number|number_attributes|Size|proof_array_\\d+\"\n",
    "name_training_data = \"formatted_run1_trial4_random_1000.csv\"\n",
    "folder_model = \"model trial 4 1000 redo\"\n",
    "n_rows = 500000\n",
    "features, labels = load_data(regex, name_training_data, n_rows) #:500000\n",
    "perform_crossval(features, labels, 1, folds=10, model= \"random\", regex = regex, name_proofs=name_training_data, output_folder=folder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trial 4 random 1000\n",
    "# regex = \"Personal Number|number_attributes|Size|proof_array_\\d+\"\n",
    "# name_training_data = \"formatted_run1_trial4_random_1000.csv\"\n",
    "# folder_model = \"model trial 4 1000 redo\"\n",
    "# n_rows = 500000\n",
    "# features, labels = load_data(regex, name_training_data, n_rows) #:500000\n",
    "perform_crossval(features, labels, 1, folds=10, model= \"random\", regex = regex, name_proofs=name_training_data, output_folder=folder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_crossval(features, labels, 2, folds=10, model= \"neuronal\", regex = regex, name_proofs=name_training_data, output_folder=\"model trial 4 100 redo\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
